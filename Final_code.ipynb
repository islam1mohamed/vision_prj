{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing (only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains available classes in this data\n",
    "\n",
    "with open(r\"D:\\Study\\Uni_Projects\\Machine Vision\\Milestone-1\\wnids.txt\" , \"r\") as f:\n",
    "    classes = []\n",
    "    for line in f :\n",
    "        line = line.removesuffix(\"\\n\")\n",
    "        classes.append(line)\n",
    "\n",
    "\n",
    "\n",
    "# contains all classes in old file\n",
    "with open(r\"D:\\Study\\Uni_Projects\\Machine Vision\\Milestone-1\\words.txt\" , \"r\") as f:\n",
    "    labels =[]\n",
    "    for line in f :\n",
    "        line = line.removesuffix(\"\\n\")\n",
    "        line = line.split(\"\\t\")\n",
    "        \n",
    "        labels.append(line)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make file with names of classes in subset (only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing = [] \n",
    "for file , label in labels:\n",
    "    if file in classes:\n",
    "        existing.append(f\"{file}-{label}\\n\")\n",
    "with open(r\"D:\\Study\\Uni_Projects\\Machine Vision\\Milestone-1\\tiny_file-class\",\"+w\") as f:\n",
    "    f.writelines(existing[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_cls = []\n",
    "with open(r\"D:\\Study\\Uni_Projects\\Machine Vision\\Milestone-1\\tiny_file-class\" , \"r\") as f :\n",
    "    for line in f :\n",
    "        line = line.strip()\n",
    "        \n",
    "        file_name , labels = line.split(\"-\", maxsplit=1)\n",
    "        labels = labels.split(\",\")\n",
    "        files_cls.append([file_name, labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'n03250847'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_dir = r\"D:\\Study\\Uni_Projects\\Machine Vision\\Milestone-1\\train-100\"\n",
    "# uses second half\n",
    "\n",
    "\n",
    "image_data = []\n",
    "\n",
    "for root, dirs, files in os.walk(train_dir):\n",
    "    for file in files:\n",
    "        if file.endswith((\".jpg\", \".JPEG\", \".png\")):\n",
    "            file_path = os.path.join(root, file)\n",
    " \n",
    "            label = os.path.basename(os.path.dirname(root))\n",
    "            \n",
    "            image_data.append((file_path, label))\n",
    "            \n",
    "\n",
    "# Print some of the data\n",
    "\n",
    "print(\"Number of images:\", len(image_data))\n",
    "\n",
    "file_path # path to each image\n",
    "label # label code of each image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/50000\n",
      "400/50000\n",
      "600/50000\n",
      "800/50000\n",
      "1000/50000\n",
      "1200/50000\n",
      "1400/50000\n",
      "1600/50000\n",
      "1800/50000\n",
      "2000/50000\n",
      "2200/50000\n",
      "2400/50000\n",
      "2600/50000\n",
      "2800/50000\n",
      "3000/50000\n",
      "3200/50000\n",
      "3400/50000\n",
      "3600/50000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(image_data)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name , \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m image_data:\n\u001b[1;32m----> 8\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m     10\u001b[0m     cv_images\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_images = []\n",
    "labels = []\n",
    "# make it np\n",
    "i = 1\n",
    "num = len(image_data)\n",
    "start_t = time.time()\n",
    "for name , cls in image_data:\n",
    "    image = cv2.imread(name)\n",
    "    labels.append(cls)\n",
    "    cv_images.append(image)\n",
    "    \n",
    "    if i%200 == 0:\n",
    "        print(f\"{i}/{num}\")\n",
    "        # break #############################\n",
    "    i=i+1\n",
    "    \n",
    "cv_images = np.array(cv_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "print(time.time()-start_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 images\n",
      "Processed 400 images\n",
      "Processed 600 images\n",
      "Processed 800 images\n",
      "Processed 1000 images\n",
      "Processed 1200 images\n",
      "Processed 1400 images\n",
      "Processed 1600 images\n",
      "Processed 1800 images\n",
      "Processed 2000 images\n",
      "Processed 2200 images\n",
      "Processed 2400 images\n",
      "Processed 2600 images\n",
      "Processed 2800 images\n",
      "Processed 3000 images\n",
      "Processed 3200 images\n",
      "Processed 3400 images\n",
      "Processed 3600 images\n",
      "Processed 3800 images\n",
      "Processed 4000 images\n",
      "Processed 4200 images\n",
      "Processed 4400 images\n",
      "Processed 4600 images\n",
      "Processed 4800 images\n",
      "Processed 5000 images\n",
      "Processed 5200 images\n",
      "Processed 5400 images\n",
      "Processed 5600 images\n",
      "Processed 5800 images\n",
      "Processed 6000 images\n",
      "Processed 6200 images\n",
      "Processed 6400 images\n",
      "Processed 6600 images\n",
      "Processed 6800 images\n",
      "Processed 7000 images\n",
      "Processed 7200 images\n",
      "Processed 7400 images\n",
      "Processed 7600 images\n",
      "Processed 7800 images\n",
      "Processed 8000 images\n",
      "Processed 8200 images\n",
      "Processed 8400 images\n",
      "Processed 8600 images\n",
      "Processed 8800 images\n",
      "Processed 9000 images\n",
      "Processed 9200 images\n",
      "Processed 9400 images\n",
      "Processed 9600 images\n",
      "Processed 9800 images\n",
      "Processed 10000 images\n",
      "Processed 10200 images\n",
      "Processed 10400 images\n",
      "Processed 10600 images\n",
      "Processed 10800 images\n",
      "Processed 11000 images\n",
      "Processed 11200 images\n",
      "Processed 11400 images\n",
      "Processed 11600 images\n",
      "Processed 11800 images\n",
      "Processed 12000 images\n",
      "Processed 12200 images\n",
      "Processed 12400 images\n",
      "Processed 12600 images\n",
      "Processed 12800 images\n",
      "Processed 13000 images\n",
      "Processed 13200 images\n",
      "Processed 13400 images\n",
      "Processed 13600 images\n",
      "Processed 13800 images\n",
      "Processed 14000 images\n",
      "Processed 14200 images\n",
      "Processed 14400 images\n",
      "Processed 14600 images\n",
      "Processed 14800 images\n",
      "Processed 15000 images\n",
      "Processed 15200 images\n",
      "Processed 15400 images\n",
      "Processed 15600 images\n",
      "Processed 15800 images\n",
      "Processed 16000 images\n",
      "Processed 16200 images\n",
      "Processed 16400 images\n",
      "Processed 16600 images\n",
      "Processed 16800 images\n",
      "Processed 17000 images\n",
      "Processed 17200 images\n",
      "Processed 17400 images\n",
      "Processed 17600 images\n",
      "Processed 17800 images\n",
      "Processed 18000 images\n",
      "Processed 18200 images\n",
      "Processed 18400 images\n",
      "Processed 18600 images\n",
      "Processed 18800 images\n",
      "Processed 19000 images\n",
      "Processed 19200 images\n",
      "Processed 19400 images\n",
      "Processed 19600 images\n",
      "Processed 19800 images\n",
      "Processed 20000 images\n",
      "Processed 20200 images\n",
      "Processed 20400 images\n",
      "Processed 20600 images\n",
      "Processed 20800 images\n",
      "Processed 21000 images\n",
      "Processed 21200 images\n",
      "Processed 21400 images\n",
      "Processed 21600 images\n",
      "Processed 21800 images\n",
      "Processed 22000 images\n",
      "Processed 22200 images\n",
      "Processed 22400 images\n",
      "Processed 22600 images\n",
      "Processed 22800 images\n",
      "Processed 23000 images\n",
      "Processed 23200 images\n",
      "Processed 23400 images\n",
      "Processed 23600 images\n",
      "Processed 23800 images\n",
      "Processed 24000 images\n",
      "Processed 24200 images\n",
      "Processed 24400 images\n",
      "Processed 24600 images\n",
      "Processed 24800 images\n",
      "Processed 25000 images\n",
      "Processed 25200 images\n",
      "Processed 25400 images\n",
      "Processed 25600 images\n",
      "Processed 25800 images\n",
      "Processed 26000 images\n",
      "Processed 26200 images\n",
      "Processed 26400 images\n",
      "Processed 26600 images\n",
      "Processed 26800 images\n",
      "Processed 27000 images\n",
      "Processed 27200 images\n",
      "Processed 27400 images\n",
      "Processed 27600 images\n",
      "Processed 27800 images\n",
      "Processed 28000 images\n",
      "Processed 28200 images\n",
      "Processed 28400 images\n",
      "Processed 28600 images\n",
      "Processed 28800 images\n",
      "Processed 29000 images\n",
      "Processed 29200 images\n",
      "Processed 29400 images\n",
      "Processed 29600 images\n",
      "Processed 29800 images\n",
      "Processed 30000 images\n",
      "Processed 30200 images\n",
      "Processed 30400 images\n",
      "Processed 30600 images\n",
      "Processed 30800 images\n",
      "Processed 31000 images\n",
      "Processed 31200 images\n",
      "Processed 31400 images\n",
      "Processed 31600 images\n",
      "Processed 31800 images\n",
      "Processed 32000 images\n",
      "Processed 32200 images\n",
      "Processed 32400 images\n",
      "Processed 32600 images\n",
      "Processed 32800 images\n",
      "Processed 33000 images\n",
      "Processed 33200 images\n",
      "Processed 33400 images\n",
      "Processed 33600 images\n",
      "Processed 33800 images\n",
      "Processed 34000 images\n",
      "Processed 34200 images\n",
      "Processed 34400 images\n",
      "Processed 34600 images\n",
      "Processed 34800 images\n",
      "Processed 35000 images\n",
      "Processed 35200 images\n",
      "Processed 35400 images\n",
      "Processed 35600 images\n",
      "Processed 35800 images\n",
      "Processed 36000 images\n",
      "Processed 36200 images\n",
      "Processed 36400 images\n",
      "Processed 36600 images\n",
      "Processed 36800 images\n",
      "Processed 37000 images\n",
      "Processed 37200 images\n",
      "Processed 37400 images\n",
      "Processed 37600 images\n",
      "Processed 37800 images\n",
      "Processed 38000 images\n",
      "Processed 38200 images\n",
      "Processed 38400 images\n",
      "Processed 38600 images\n",
      "Processed 38800 images\n",
      "Processed 39000 images\n",
      "Processed 39200 images\n",
      "Processed 39400 images\n",
      "Processed 39600 images\n",
      "Processed 39800 images\n",
      "Processed 40000 images\n",
      "Processed 40200 images\n",
      "Processed 40400 images\n",
      "Processed 40600 images\n",
      "Processed 40800 images\n",
      "Processed 41000 images\n",
      "Processed 41200 images\n",
      "Processed 41400 images\n",
      "Processed 41600 images\n",
      "Processed 41800 images\n",
      "Processed 42000 images\n",
      "Processed 42200 images\n",
      "Processed 42400 images\n",
      "Processed 42600 images\n",
      "Processed 42800 images\n",
      "Processed 43000 images\n",
      "Processed 43200 images\n",
      "Processed 43400 images\n",
      "Processed 43600 images\n",
      "Processed 43800 images\n",
      "Processed 44000 images\n",
      "Processed 44200 images\n",
      "Processed 44400 images\n",
      "Processed 44600 images\n",
      "Processed 44800 images\n",
      "Processed 45000 images\n",
      "Processed 45200 images\n",
      "Processed 45400 images\n",
      "Processed 45600 images\n",
      "Processed 45800 images\n",
      "Processed 46000 images\n",
      "Processed 46200 images\n",
      "Processed 46400 images\n",
      "Processed 46600 images\n",
      "Processed 46800 images\n",
      "Processed 47000 images\n",
      "Processed 47200 images\n",
      "Processed 47400 images\n",
      "Processed 47600 images\n",
      "Processed 47800 images\n",
      "Processed 48000 images\n",
      "Processed 48200 images\n",
      "Processed 48400 images\n",
      "Processed 48600 images\n",
      "Processed 48800 images\n",
      "Processed 49000 images\n",
      "Processed 49200 images\n",
      "Processed 49400 images\n",
      "Processed 49600 images\n",
      "Processed 49800 images\n",
      "Processed 50000 images\n",
      "HOG features: (50000, 1764)\n",
      "LBP features: (50000, 26)\n",
      "Color Histogram features: (50000, 96)\n",
      "LBP 64 features: (50000, 26)\n",
      "Color Histogram 64 features: (50000, 96)\n"
     ]
    }
   ],
   "source": [
    "from skimage.feature import hog , local_binary_pattern\n",
    "\n",
    "# HOG \n",
    "def extract_hog(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features, _ = hog(gray_image, orientations=9, pixels_per_cell=(8,8),\n",
    "                      cells_per_block=(2, 2), block_norm='L2-Hys',\n",
    "                      visualize=True, feature_vector=True)\n",
    "    return features\n",
    "\n",
    "# LBP \n",
    "def extract_lbp(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray_image, n_points, radius, method=\"uniform\")\n",
    "    \n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), density=True)\n",
    "    return lbp_hist\n",
    "\n",
    "# Color \n",
    "\n",
    "def extract_color_hist(image):\n",
    "    hist_red = cv2.calcHist([image], [0], None, [32], [0, 256])\n",
    "    hist_green = cv2.calcHist([image], [1], None, [32], [0, 256])\n",
    "    hist_blue = cv2.calcHist([image], [2], None, [32], [0, 256])\n",
    "    color_hist = np.concatenate([hist_red, hist_green, hist_blue]).flatten()\n",
    "    return color_hist / color_hist.sum()  # Normalize\n",
    "\n",
    "\n",
    "# reduce size for trial\n",
    "\n",
    "# cv_images = cv_images[:10000]\n",
    "# labels = labels[:10]\n",
    "\n",
    "hog_features = []\n",
    "lbp_features = []\n",
    "color_hist_features = []\n",
    "lbp_features64 = []\n",
    "color_hist_features64 = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 1\n",
    "for image in cv_images:\n",
    "    if image is None:  # Skip invalid images\n",
    "        continue\n",
    "\n",
    "    # Resize the image to a fixed size for consistency\n",
    "    image_resized = cv2.resize(image, (128, 128))\n",
    "\n",
    "\n",
    "    # here we increased resolution for ibp and color to get better results as their computation cost is quite small\n",
    "    hog_feat = extract_hog(image)\n",
    "    lbp_feat64 = extract_lbp(image)\n",
    "    color_feat64 = extract_color_hist(image)\n",
    "    \n",
    "    lbp_feat = extract_lbp(image_resized)\n",
    "    color_feat = extract_color_hist(image_resized)\n",
    "    \n",
    "    # Append to respective lists\n",
    "    hog_features.append(hog_feat)\n",
    "    lbp_features.append(lbp_feat)\n",
    "    color_hist_features.append(color_feat)\n",
    "    \n",
    "    lbp_features64.append(lbp_feat64)\n",
    "    color_hist_features64.append(color_feat64)\n",
    "    \n",
    "    if i % 400 == 0:\n",
    "        print(f\"Processed {i} images\")\n",
    "    i += 1\n",
    "\n",
    "# Convert lists to NumPy arrays for further processing\n",
    "hog_features = np.array(hog_features)\n",
    "lbp_features = np.array(lbp_features)\n",
    "color_hist_features = np.array(color_hist_features)\n",
    "lbp_features64 = np.array(lbp_features64)\n",
    "color_hist_features64 = np.array(color_hist_features64)\n",
    "\n",
    "\n",
    "print(f\"HOG features: {hog_features.shape}\")\n",
    "print(f\"LBP features: {lbp_features.shape}\")\n",
    "print(f\"Color Histogram features: {color_hist_features.shape}\")\n",
    "print(f\"LBP 64 features: {lbp_features64.shape}\")\n",
    "print(f\"Color Histogram 64 features: {color_hist_features64.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "def kmeans_clustering(features, num_clusters, max_iters=30, tol=1e-4):\n",
    "    np.random.seed(40)\n",
    "    centers = features[np.random.choice(features.shape[0], num_clusters, replace=False)]\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        distances = np.linalg.norm(features[:, np.newaxis] - centers, axis=2)\n",
    "        cluster_labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        new_centers = np.array([features[cluster_labels == k].mean(axis=0) for k in range(num_clusters)])\n",
    "        if np.linalg.norm(new_centers - centers) < tol:\n",
    "            break\n",
    "        centers = new_centers\n",
    "    \n",
    "        print(f\"step {i}\")\n",
    "    return cluster_labels, centers\n",
    "\n",
    "\n",
    "\n",
    "def knn_predict(train_features, train_labels, test_features, k=10):\n",
    "    predictions = []\n",
    "    num = len(test_features)\n",
    "    batch_size = 50  # Process test samples in batches for better memory utilization\n",
    "    num_batches = (num + batch_size - 1) // batch_size\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, num)\n",
    "        test_batch = test_features[start_idx:end_idx]\n",
    "        \n",
    "        distances = np.linalg.norm(train_features[:, None, :] - test_batch[None, :, :], axis=2)  # Shape: (train_size, batch_size)\n",
    "        \n",
    "        # Find nearest neighbors\n",
    "        nearest_indices = np.argsort(distances, axis=0)[:k, :] \n",
    "        nearest_labels = train_labels[nearest_indices]  # Get the labels of the nearest neighbors\n",
    "        \n",
    "        # Determine the most common label for each test sample\n",
    "        batch_predictions = [Counter(nearest_labels[:, col]).most_common(1)[0][0] for col in range(test_batch.shape[0])]\n",
    "        predictions.extend(batch_predictions)\n",
    "        \n",
    "        print(f\"Batch {batch_idx + 1}/{num_batches} completed\")\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "def train_svm(train_features, train_labels):\n",
    "    svm = SVC(kernel=\"linear\", C=1.0)\n",
    "    svm.fit(train_features, train_labels)\n",
    "    return svm\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def assign_label_to_centers(centers, data, labels, num_closest=500):\n",
    "\n",
    "    center_labels = {}\n",
    "\n",
    "    distances = cdist(centers, data, metric='euclidean')  # Shape: (num_centers x num_samples)\n",
    "\n",
    "    for center_idx, center_distances in enumerate(distances):\n",
    "        closest_indices = np.argsort(center_distances)[:num_closest]\n",
    "        closest_labels = labels[closest_indices]\n",
    "        most_common_label, count = Counter(closest_labels).most_common(1)[0]\n",
    "        center_labels[center_idx] = (most_common_label, count)\n",
    "\n",
    "    return center_labels\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_test_accuracy(centers, center_labels, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Compute the prediction accuracy using cluster centers on the test set.\n",
    "\n",
    "    Parameters:\n",
    "    - centers (np.ndarray): Cluster centers (shape: num_clusters x num_features).\n",
    "    - center_labels (dict): Dictionary mapping center indices to their labels.\n",
    "    - X_test (np.ndarray): Test dataset (shape: num_test_samples x num_features).\n",
    "    - y_test (np.ndarray): True labels for the test dataset (shape: num_test_samples).\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Accuracy of predictions on the test set.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for test_sample in X_test:\n",
    "        # Compute distances from test_sample to all cluster centers\n",
    "        distances = np.linalg.norm(centers - test_sample, axis=1)\n",
    "        \n",
    "        # Find the index of the closest center\n",
    "        closest_center_idx = np.argmin(distances)\n",
    "        \n",
    "        # Get the label of the closest center\n",
    "        predicted_label = center_labels[closest_center_idx]\n",
    "        predictions.append(predicted_label)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hog_features_array = np.array(hog_features)\n",
    "lbp_features_array = np.array(lbp_features)\n",
    "color_hist_features_array = np.array(color_hist_features)\n",
    "lbp_features_array64 = np.array(lbp_features64)\n",
    "color_hist_features_array64 = np.array(color_hist_features64)\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# Split Data into Training and Testing\n",
    "X_train_hog, X_test_hog, y_train, y_test = train_test_split(hog_features_array, labels_array, test_size=0.2, random_state=42)\n",
    "X_train_lbp, X_test_lbp, y_train_lbp, y_test_lbp= train_test_split(lbp_features_array, labels_array, test_size=0.2, random_state=42)\n",
    "X_train_color, X_test_color, y_train_color , y_test_color = train_test_split(color_hist_features_array, labels_array, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_lbp64, X_test_lbp64, y_train_lbp64, y_test_lbp64= train_test_split(lbp_features_array64, labels_array, test_size=0.2, random_state=42)\n",
    "X_train_color64, X_test_color64, y_train_color64 , y_test_color64 = train_test_split(color_hist_features_array64, labels_array, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "SVM (HOG) Accuracy: 0.0995, takiing: 1980.5473673343658 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training SVM...\")\n",
    "start_time = time.time()\n",
    "svm_model_hog = train_svm(X_train_hog, y_train)\n",
    "svm_predictions_hog = svm_model_hog.predict(X_test_hog)\n",
    "svm_accuracy_hog = accuracy_score(y_test, svm_predictions_hog)\n",
    "print(f\"SVM (HOG) Accuracy: {svm_accuracy_hog}, takiing: {time.time()-start_time} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training K-Nearest Neighbors for color...\n",
      "Batch 1/200 completed\n",
      "Batch 2/200 completed\n",
      "Batch 3/200 completed\n",
      "Batch 4/200 completed\n",
      "Batch 5/200 completed\n",
      "Batch 6/200 completed\n",
      "Batch 7/200 completed\n",
      "Batch 8/200 completed\n",
      "Batch 9/200 completed\n",
      "Batch 10/200 completed\n",
      "Batch 11/200 completed\n",
      "Batch 12/200 completed\n",
      "Batch 13/200 completed\n",
      "Batch 14/200 completed\n",
      "Batch 15/200 completed\n",
      "Batch 16/200 completed\n",
      "Batch 17/200 completed\n",
      "Batch 18/200 completed\n",
      "Batch 19/200 completed\n",
      "Batch 20/200 completed\n",
      "Batch 21/200 completed\n",
      "Batch 22/200 completed\n",
      "Batch 23/200 completed\n",
      "Batch 24/200 completed\n",
      "Batch 25/200 completed\n",
      "Batch 26/200 completed\n",
      "Batch 27/200 completed\n",
      "Batch 28/200 completed\n",
      "Batch 29/200 completed\n",
      "Batch 30/200 completed\n",
      "Batch 31/200 completed\n",
      "Batch 32/200 completed\n",
      "Batch 33/200 completed\n",
      "Batch 34/200 completed\n",
      "Batch 35/200 completed\n",
      "Batch 36/200 completed\n",
      "Batch 37/200 completed\n",
      "Batch 38/200 completed\n",
      "Batch 39/200 completed\n",
      "Batch 40/200 completed\n",
      "Batch 41/200 completed\n",
      "Batch 42/200 completed\n",
      "Batch 43/200 completed\n",
      "Batch 44/200 completed\n",
      "Batch 45/200 completed\n",
      "Batch 46/200 completed\n",
      "Batch 47/200 completed\n",
      "Batch 48/200 completed\n",
      "Batch 49/200 completed\n",
      "Batch 50/200 completed\n",
      "Batch 51/200 completed\n",
      "Batch 52/200 completed\n",
      "Batch 53/200 completed\n",
      "Batch 54/200 completed\n",
      "Batch 55/200 completed\n",
      "Batch 56/200 completed\n",
      "Batch 57/200 completed\n",
      "Batch 58/200 completed\n",
      "Batch 59/200 completed\n",
      "Batch 60/200 completed\n",
      "Batch 61/200 completed\n",
      "Batch 62/200 completed\n",
      "Batch 63/200 completed\n",
      "Batch 64/200 completed\n",
      "Batch 65/200 completed\n",
      "Batch 66/200 completed\n",
      "Batch 67/200 completed\n",
      "Batch 68/200 completed\n",
      "Batch 69/200 completed\n",
      "Batch 70/200 completed\n",
      "Batch 71/200 completed\n",
      "Batch 72/200 completed\n",
      "Batch 73/200 completed\n",
      "Batch 74/200 completed\n",
      "Batch 75/200 completed\n",
      "Batch 76/200 completed\n",
      "Batch 77/200 completed\n",
      "Batch 78/200 completed\n",
      "Batch 79/200 completed\n",
      "Batch 80/200 completed\n",
      "Batch 81/200 completed\n",
      "Batch 82/200 completed\n",
      "Batch 83/200 completed\n",
      "Batch 84/200 completed\n",
      "Batch 85/200 completed\n",
      "Batch 86/200 completed\n",
      "Batch 87/200 completed\n",
      "Batch 88/200 completed\n",
      "Batch 89/200 completed\n",
      "Batch 90/200 completed\n",
      "Batch 91/200 completed\n",
      "Batch 92/200 completed\n",
      "Batch 93/200 completed\n",
      "Batch 94/200 completed\n",
      "Batch 95/200 completed\n",
      "Batch 96/200 completed\n",
      "Batch 97/200 completed\n",
      "Batch 98/200 completed\n",
      "Batch 99/200 completed\n",
      "Batch 100/200 completed\n",
      "Batch 101/200 completed\n",
      "Batch 102/200 completed\n",
      "Batch 103/200 completed\n",
      "Batch 104/200 completed\n",
      "Batch 105/200 completed\n",
      "Batch 106/200 completed\n",
      "Batch 107/200 completed\n",
      "Batch 108/200 completed\n",
      "Batch 109/200 completed\n",
      "Batch 110/200 completed\n",
      "Batch 111/200 completed\n",
      "Batch 112/200 completed\n",
      "Batch 113/200 completed\n",
      "Batch 114/200 completed\n",
      "Batch 115/200 completed\n",
      "Batch 116/200 completed\n",
      "Batch 117/200 completed\n",
      "Batch 118/200 completed\n",
      "Batch 119/200 completed\n",
      "Batch 120/200 completed\n",
      "Batch 121/200 completed\n",
      "Batch 122/200 completed\n",
      "Batch 123/200 completed\n",
      "Batch 124/200 completed\n",
      "Batch 125/200 completed\n",
      "Batch 126/200 completed\n",
      "Batch 127/200 completed\n",
      "Batch 128/200 completed\n",
      "Batch 129/200 completed\n",
      "Batch 130/200 completed\n",
      "Batch 131/200 completed\n",
      "Batch 132/200 completed\n",
      "Batch 133/200 completed\n",
      "Batch 134/200 completed\n",
      "Batch 135/200 completed\n",
      "Batch 136/200 completed\n",
      "Batch 137/200 completed\n",
      "Batch 138/200 completed\n",
      "Batch 139/200 completed\n",
      "Batch 140/200 completed\n",
      "Batch 141/200 completed\n",
      "Batch 142/200 completed\n",
      "Batch 143/200 completed\n",
      "Batch 144/200 completed\n",
      "Batch 145/200 completed\n",
      "Batch 146/200 completed\n",
      "Batch 147/200 completed\n",
      "Batch 148/200 completed\n",
      "Batch 149/200 completed\n",
      "Batch 150/200 completed\n",
      "Batch 151/200 completed\n",
      "Batch 152/200 completed\n",
      "Batch 153/200 completed\n",
      "Batch 154/200 completed\n",
      "Batch 155/200 completed\n",
      "Batch 156/200 completed\n",
      "Batch 157/200 completed\n",
      "Batch 158/200 completed\n",
      "Batch 159/200 completed\n",
      "Batch 160/200 completed\n",
      "Batch 161/200 completed\n",
      "Batch 162/200 completed\n",
      "Batch 163/200 completed\n",
      "Batch 164/200 completed\n",
      "Batch 165/200 completed\n",
      "Batch 166/200 completed\n",
      "Batch 167/200 completed\n",
      "Batch 168/200 completed\n",
      "Batch 169/200 completed\n",
      "Batch 170/200 completed\n",
      "Batch 171/200 completed\n",
      "Batch 172/200 completed\n",
      "Batch 173/200 completed\n",
      "Batch 174/200 completed\n",
      "Batch 175/200 completed\n",
      "Batch 176/200 completed\n",
      "Batch 177/200 completed\n",
      "Batch 178/200 completed\n",
      "Batch 179/200 completed\n",
      "Batch 180/200 completed\n",
      "Batch 181/200 completed\n",
      "Batch 182/200 completed\n",
      "Batch 183/200 completed\n",
      "Batch 184/200 completed\n",
      "Batch 185/200 completed\n",
      "Batch 186/200 completed\n",
      "Batch 187/200 completed\n",
      "Batch 188/200 completed\n",
      "Batch 189/200 completed\n",
      "Batch 190/200 completed\n",
      "Batch 191/200 completed\n",
      "Batch 192/200 completed\n",
      "Batch 193/200 completed\n",
      "Batch 194/200 completed\n",
      "Batch 195/200 completed\n",
      "Batch 196/200 completed\n",
      "Batch 197/200 completed\n",
      "Batch 198/200 completed\n",
      "Batch 199/200 completed\n",
      "Batch 200/200 completed\n",
      "K-Nearest Neighbors (color) Accuracy: 0.0623, taking: 140.35754227638245 sec\n",
      "Training SVM for color...\n",
      "SVM (color) Accuracy: 0.0358, taking: 204.36728858947754 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # 1. K-Means Clustering\n",
    "# print(\"Training K-Means for LBP...\")\n",
    "# start_time = time.time()\n",
    "# num_clusters = len(np.unique(labels_array))\n",
    "\n",
    "# kmeans_labels_color, kmeans_center_color = kmeans_clustering(X_train_color, num_clusters)\n",
    "\n",
    "# print(f\"K-Means (LBP) clustering complete, taking: {time.time() - start_time} sec\")\n",
    "\n",
    "\n",
    "# 2. KNN\n",
    "print(\"Training K-Nearest Neighbors for color...\")\n",
    "start_time = time.time()\n",
    "knn_predictions_color = knn_predict(X_train_color, y_train_color, X_test_color, k=10)\n",
    "knn_accuracy_color = accuracy_score(y_test_color, knn_predictions_color)\n",
    "print(f\"K-Nearest Neighbors (color) Accuracy: {knn_accuracy_color}, taking: {time.time() - start_time} sec\")\n",
    "\n",
    "# 3. SVM\n",
    "print(\"Training SVM for color...\")\n",
    "start_time = time.time()\n",
    "svm_model_color = train_svm(X_train_color, y_train_color)\n",
    "svm_predictions_color = svm_model_color.predict(X_test_color)\n",
    "svm_accuracy_color= accuracy_score(y_test_color, svm_predictions_color)\n",
    "print(f\"SVM (color) Accuracy: {svm_accuracy_color}, taking: {time.time() - start_time} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kmean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmean\n",
    "def kmeans_clustering(features, num_clusters, max_iters=30, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Performs K-Means clustering without relying on cluster labels.\n",
    "    \n",
    "    Args:\n",
    "        features (np.ndarray): The input data to cluster.\n",
    "        num_clusters (int): Number of clusters.\n",
    "        max_iters (int): Maximum iterations for convergence.\n",
    "        tol (float): Tolerance for convergence.\n",
    "\n",
    "    Returns:\n",
    "        centers (np.ndarray): The cluster centers.\n",
    "    \"\"\"\n",
    "    np.random.seed(40)\n",
    "    centers = features[np.random.choice(features.shape[0], num_clusters, replace=False)]\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        # Calculate distances and assign points to the nearest center\n",
    "        distances = np.linalg.norm(features[:, np.newaxis] - centers, axis=2)\n",
    "        cluster_labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # Update centers\n",
    "        new_centers = np.array([features[cluster_labels == k].mean(axis=0) for k in range(num_clusters)])\n",
    "        if np.linalg.norm(new_centers - centers) < tol:\n",
    "            break\n",
    "        centers = new_centers\n",
    "        \n",
    "        print(f\"step {i}\")\n",
    "    \n",
    "    return centers\n",
    "\n",
    "\n",
    "def assign_labels_to_clusters(centers, features, labels, k=500):\n",
    "    \"\"\"\n",
    "    Assigns a label to each cluster based on the most frequent label \n",
    "    among the closest `k` points to the center.\n",
    "\n",
    "    Args:\n",
    "        centers (np.ndarray): Cluster centers.\n",
    "        features (np.ndarray): Input data.\n",
    "        labels (np.ndarray): Corresponding labels for the input data.\n",
    "        k (int): Number of closest points to consider.\n",
    "\n",
    "    Returns:\n",
    "        cluster_labels (dict): A dictionary mapping center indices to labels.\n",
    "    \"\"\"\n",
    "    cluster_labels = {}\n",
    "    \n",
    "    for idx, center in enumerate(centers):\n",
    "        # Compute distances to all features\n",
    "        distances = np.linalg.norm(features - center, axis=1)\n",
    "        nearest_indices = np.argsort(distances)[:k]\n",
    "        nearest_labels = labels[nearest_indices]\n",
    "\n",
    "        most_common_label = Counter(nearest_labels).most_common(1)[0][0]\n",
    "        cluster_labels[idx] = most_common_label\n",
    "    \n",
    "    return cluster_labels\n",
    "\n",
    "\n",
    "def predict_using_kmeans(centers, cluster_labels, test_features):\n",
    "    \"\"\"\n",
    "    Predicts the labels for test data based on the closest cluster center.\n",
    "\n",
    "    Args:\n",
    "        centers (np.ndarray): Cluster centers.\n",
    "        cluster_labels (dict): Mapping of cluster indices to labels.\n",
    "        test_features (np.ndarray): Test data.\n",
    "\n",
    "    Returns:\n",
    "        predictions (np.ndarray): Predicted labels for the test data.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for test_sample in test_features:\n",
    "        # Find the nearest center\n",
    "        distances = np.linalg.norm(centers - test_sample, axis=1)\n",
    "        nearest_center_idx = np.argmin(distances)\n",
    "        \n",
    "        # Use the label of the nearest center\n",
    "        predictions.append(cluster_labels[nearest_center_idx])\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "num_clusters = len(np.unique(labels_array))\n",
    "\n",
    "# Train K-Means without labels\n",
    "centers = kmeans_clustering(X_train_color, num_clusters)\n",
    "\n",
    "cluster_labels = assign_labels_to_clusters(centers, X_train_color, y_train_color, k=500)\n",
    "kmeans_predictions = predict_using_kmeans(centers, cluster_labels, X_test_color)\n",
    "kmeans_accuracy = accuracy_score(y_test_color, kmeans_predictions)\n",
    "print(f\"K-Means Accuracy: {kmeans_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training K-Nearest Neighbors for LBP...\n",
      "Batch 1/200 completed\n",
      "Batch 2/200 completed\n",
      "Batch 3/200 completed\n",
      "Batch 4/200 completed\n",
      "Batch 5/200 completed\n",
      "Batch 6/200 completed\n",
      "Batch 7/200 completed\n",
      "Batch 8/200 completed\n",
      "Batch 9/200 completed\n",
      "Batch 10/200 completed\n",
      "Batch 11/200 completed\n",
      "Batch 12/200 completed\n",
      "Batch 13/200 completed\n",
      "Batch 14/200 completed\n",
      "Batch 15/200 completed\n",
      "Batch 16/200 completed\n",
      "Batch 17/200 completed\n",
      "Batch 18/200 completed\n",
      "Batch 19/200 completed\n",
      "Batch 20/200 completed\n",
      "Batch 21/200 completed\n",
      "Batch 22/200 completed\n",
      "Batch 23/200 completed\n",
      "Batch 24/200 completed\n",
      "Batch 25/200 completed\n",
      "Batch 26/200 completed\n",
      "Batch 27/200 completed\n",
      "Batch 28/200 completed\n",
      "Batch 29/200 completed\n",
      "Batch 30/200 completed\n",
      "Batch 31/200 completed\n",
      "Batch 32/200 completed\n",
      "Batch 33/200 completed\n",
      "Batch 34/200 completed\n",
      "Batch 35/200 completed\n",
      "Batch 36/200 completed\n",
      "Batch 37/200 completed\n",
      "Batch 38/200 completed\n",
      "Batch 39/200 completed\n",
      "Batch 40/200 completed\n",
      "Batch 41/200 completed\n",
      "Batch 42/200 completed\n",
      "Batch 43/200 completed\n",
      "Batch 44/200 completed\n",
      "Batch 45/200 completed\n",
      "Batch 46/200 completed\n",
      "Batch 47/200 completed\n",
      "Batch 48/200 completed\n",
      "Batch 49/200 completed\n",
      "Batch 50/200 completed\n",
      "Batch 51/200 completed\n",
      "Batch 52/200 completed\n",
      "Batch 53/200 completed\n",
      "Batch 54/200 completed\n",
      "Batch 55/200 completed\n",
      "Batch 56/200 completed\n",
      "Batch 57/200 completed\n",
      "Batch 58/200 completed\n",
      "Batch 59/200 completed\n",
      "Batch 60/200 completed\n",
      "Batch 61/200 completed\n",
      "Batch 62/200 completed\n",
      "Batch 63/200 completed\n",
      "Batch 64/200 completed\n",
      "Batch 65/200 completed\n",
      "Batch 66/200 completed\n",
      "Batch 67/200 completed\n",
      "Batch 68/200 completed\n",
      "Batch 69/200 completed\n",
      "Batch 70/200 completed\n",
      "Batch 71/200 completed\n",
      "Batch 72/200 completed\n",
      "Batch 73/200 completed\n",
      "Batch 74/200 completed\n",
      "Batch 75/200 completed\n",
      "Batch 76/200 completed\n",
      "Batch 77/200 completed\n",
      "Batch 78/200 completed\n",
      "Batch 79/200 completed\n",
      "Batch 80/200 completed\n",
      "Batch 81/200 completed\n",
      "Batch 82/200 completed\n",
      "Batch 83/200 completed\n",
      "Batch 84/200 completed\n",
      "Batch 85/200 completed\n",
      "Batch 86/200 completed\n",
      "Batch 87/200 completed\n",
      "Batch 88/200 completed\n",
      "Batch 89/200 completed\n",
      "Batch 90/200 completed\n",
      "Batch 91/200 completed\n",
      "Batch 92/200 completed\n",
      "Batch 93/200 completed\n",
      "Batch 94/200 completed\n",
      "Batch 95/200 completed\n",
      "Batch 96/200 completed\n",
      "Batch 97/200 completed\n",
      "Batch 98/200 completed\n",
      "Batch 99/200 completed\n",
      "Batch 100/200 completed\n",
      "Batch 101/200 completed\n",
      "Batch 102/200 completed\n",
      "Batch 103/200 completed\n",
      "Batch 104/200 completed\n",
      "Batch 105/200 completed\n",
      "Batch 106/200 completed\n",
      "Batch 107/200 completed\n",
      "Batch 108/200 completed\n",
      "Batch 109/200 completed\n",
      "Batch 110/200 completed\n",
      "Batch 111/200 completed\n",
      "Batch 112/200 completed\n",
      "Batch 113/200 completed\n",
      "Batch 114/200 completed\n",
      "Batch 115/200 completed\n",
      "Batch 116/200 completed\n",
      "Batch 117/200 completed\n",
      "Batch 118/200 completed\n",
      "Batch 119/200 completed\n",
      "Batch 120/200 completed\n",
      "Batch 121/200 completed\n",
      "Batch 122/200 completed\n",
      "Batch 123/200 completed\n",
      "Batch 124/200 completed\n",
      "Batch 125/200 completed\n",
      "Batch 126/200 completed\n",
      "Batch 127/200 completed\n",
      "Batch 128/200 completed\n",
      "Batch 129/200 completed\n",
      "Batch 130/200 completed\n",
      "Batch 131/200 completed\n",
      "Batch 132/200 completed\n",
      "Batch 133/200 completed\n",
      "Batch 134/200 completed\n",
      "Batch 135/200 completed\n",
      "Batch 136/200 completed\n",
      "Batch 137/200 completed\n",
      "Batch 138/200 completed\n",
      "Batch 139/200 completed\n",
      "Batch 140/200 completed\n",
      "Batch 141/200 completed\n",
      "Batch 142/200 completed\n",
      "Batch 143/200 completed\n",
      "Batch 144/200 completed\n",
      "Batch 145/200 completed\n",
      "Batch 146/200 completed\n",
      "Batch 147/200 completed\n",
      "Batch 148/200 completed\n",
      "Batch 149/200 completed\n",
      "Batch 150/200 completed\n",
      "Batch 151/200 completed\n",
      "Batch 152/200 completed\n",
      "Batch 153/200 completed\n",
      "Batch 154/200 completed\n",
      "Batch 155/200 completed\n",
      "Batch 156/200 completed\n",
      "Batch 157/200 completed\n",
      "Batch 158/200 completed\n",
      "Batch 159/200 completed\n",
      "Batch 160/200 completed\n",
      "Batch 161/200 completed\n",
      "Batch 162/200 completed\n",
      "Batch 163/200 completed\n",
      "Batch 164/200 completed\n",
      "Batch 165/200 completed\n",
      "Batch 166/200 completed\n",
      "Batch 167/200 completed\n",
      "Batch 168/200 completed\n",
      "Batch 169/200 completed\n",
      "Batch 170/200 completed\n",
      "Batch 171/200 completed\n",
      "Batch 172/200 completed\n",
      "Batch 173/200 completed\n",
      "Batch 174/200 completed\n",
      "Batch 175/200 completed\n",
      "Batch 176/200 completed\n",
      "Batch 177/200 completed\n",
      "Batch 178/200 completed\n",
      "Batch 179/200 completed\n",
      "Batch 180/200 completed\n",
      "Batch 181/200 completed\n",
      "Batch 182/200 completed\n",
      "Batch 183/200 completed\n",
      "Batch 184/200 completed\n",
      "Batch 185/200 completed\n",
      "Batch 186/200 completed\n",
      "Batch 187/200 completed\n",
      "Batch 188/200 completed\n",
      "Batch 189/200 completed\n",
      "Batch 190/200 completed\n",
      "Batch 191/200 completed\n",
      "Batch 192/200 completed\n",
      "Batch 193/200 completed\n",
      "Batch 194/200 completed\n",
      "Batch 195/200 completed\n",
      "Batch 196/200 completed\n",
      "Batch 197/200 completed\n",
      "Batch 198/200 completed\n",
      "Batch 199/200 completed\n",
      "Batch 200/200 completed\n",
      "K-Nearest Neighbors (LBP) Accuracy: 0.0451, taking: 93.38667607307434 sec\n",
      "Training SVM for LBP...\n",
      "SVM (LBP) Accuracy: 0.0251, taking: 165.68236136436462 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # 1. K-Means Clustering\n",
    "# print(\"Training K-Means for LBP...\")\n",
    "# start_time = time.time()\n",
    "# num_clusters = len(np.unique(labels_array))\n",
    "# kmeans_labels_lbp, _ = kmeans_clustering(X_train_lbp, num_clusters)\n",
    "# knn_accuracy_lbp = accuracy_score(y_test_lbp, kmeans_labels_lbp)\n",
    "# print(f\"K-Means (LBP) clustering complete, taking: {time.time() - start_time} sec\")\n",
    "\n",
    "\n",
    "# 2. K-Nearest Neighbors\n",
    "print(\"Training K-Nearest Neighbors for LBP...\")\n",
    "start_time = time.time()\n",
    "knn_predictions_lbp = knn_predict(X_train_lbp, y_train_lbp, X_test_lbp, k=10)\n",
    "knn_accuracy_lbp = accuracy_score(y_test_lbp, knn_predictions_lbp)\n",
    "print(f\"K-Nearest Neighbors (LBP) Accuracy: {knn_accuracy_lbp}, taking: {time.time() - start_time} sec\")\n",
    "\n",
    "# 3. Support Vector Machine (SVM)\n",
    "print(\"Training SVM for LBP...\")\n",
    "start_time = time.time()\n",
    "svm_model_lbp = train_svm(X_train_lbp, y_train_lbp)\n",
    "svm_predictions_lbp = svm_model_lbp.predict(X_test_lbp)\n",
    "svm_accuracy_lbp = accuracy_score(y_test_lbp, svm_predictions_lbp)\n",
    "print(f\"SVM (LBP) Accuracy: {svm_accuracy_lbp}, taking: {time.time() - start_time} sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f\"m1acc\",\"+w\") as f:\n",
    "    \n",
    "    f.write(f\"svm_hog acc {svm_accuracy_hog} \\nsvm_lbp acc {svm_accuracy_lbp} \\nknn_lbp acc  {knn_accuracy_lbp} \")\n",
    "    f.write(f\"knn_color acc {knn_accuracy_color} \\nsvm_lbp acc {svm_accuracy_lbp} \\nknn_lbp acc  {knn_accuracy_lbp} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
